{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore random forest bootstrap sample size on performance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import arange\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    # explore ratios from 10% to 100% in 10% increments\n",
    "    for i in arange(0.1, 1.1, 0.1):\n",
    "        key = '%.1f' % i\n",
    "        # set max_samples=None to use 100%\n",
    "        if i == 1.0:\n",
    "            i = None\n",
    "        models[key] = RandomForestClassifier(max_samples=i)\n",
    "    return models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    # define the evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # evaluate the model and collect the results\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')  \n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "#state_train = pd.get_dummies(train.user_state, prefix='state')\n",
    "#train = pd.concat([train, state_train], axis=1)\n",
    "train.drop(['user_state'], axis=1, inplace=True)\n",
    "\n",
    "#state_test = pd.get_dummies(test.user_state, prefix='state')\n",
    "#test = pd.concat([test, state_test], axis=1)\n",
    "test.drop(['user_state'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('click', axis=1)\n",
    "y_train = train['click']\n",
    "\n",
    "X_test = test.drop('click', axis=1)\n",
    "y_test = test['click']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.1 0.921 (0.000)\n",
      ">0.2 0.921 (0.000)\n",
      ">0.3 0.920 (0.000)\n"
     ]
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X_test, y_test)\n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    # summarize the performance along the way\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
